# EM-epsilon-
期望最大化（EM）算法是一种在缺失数据问题中获得最大似然估计的方法。由于其简单性、灵活性和稳定性（似然性单调增加）,EM算法得到工业界和学术界的广泛关注、研究和应用。但是，在许多应用中，EM算法收敛非常缓慢，因此很多学者提出了各种用于加速EM算法收敛速度的方法。受前人的研究——应用向量型$\Delta^{2}$方法加速EM算法的启发，本文考虑两种向量型收敛加速方法即迭代的$\Delta^{2}$方法和$\varepsilon$算法在EM算法加速中的应用，并提供了理论证明和数值模拟来证实这些方法比向量型$\Delta^{2}$方法的加速效果更好。本文考虑的这两个EM算法的加速方法不仅继承了EM算法的优点，而且在收敛条件更苛刻时它们表现更为出色。对这两种方法的程序，使用者只需要做微小而必要的修改(如：EM算法迭代公式和参数初始化)，不需要对不同模型作专门的算法设计，就可以为所有利用EM算法的统计模型进行加速，具有通用性、易操作的特点。本文提供四个模型示例来展示他们的有效性，用Rstudio编写。
